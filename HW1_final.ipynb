{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Niv0902/EcoFish-/blob/main/HW1_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee1607cd",
      "metadata": {
        "id": "ee1607cd"
      },
      "source": [
        "# Ecological RAG System – Premium Edition 🌊\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c35bd35e",
      "metadata": {
        "id": "c35bd35e"
      },
      "outputs": [],
      "source": [
        "# If running on Colab, uncomment to install dependencies:\n",
        "# !pip -q install gradio==4.* sentence-transformers chromadb scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "66480b70",
      "metadata": {
        "id": "66480b70"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any, Optional\n",
        "import re\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a87c40c8",
      "metadata": {
        "id": "a87c40c8"
      },
      "outputs": [],
      "source": [
        "# Package detection\n",
        "try:\n",
        "    import chromadb\n",
        "    CHROMADB_AVAILABLE = True\n",
        "except ImportError:\n",
        "    CHROMADB_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    TRANSFORMERS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    TRANSFORMERS_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    import openai\n",
        "    OPENAI_AVAILABLE = True\n",
        "except ImportError:\n",
        "    OPENAI_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    import gradio as gr\n",
        "    GRADIO_AVAILABLE = True\n",
        "except ImportError:\n",
        "    GRADIO_AVAILABLE = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "56a384b8",
      "metadata": {
        "id": "56a384b8"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9ac5bece",
      "metadata": {
        "id": "9ac5bece"
      },
      "outputs": [],
      "source": [
        "class SimpleVectorStore:\n",
        "    \"\"\"Lightweight vector store for when ChromaDB is unavailable\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.documents = []\n",
        "        self.embeddings = []\n",
        "        self.metadatas = []\n",
        "        self.ids = []\n",
        "\n",
        "    def add(self, embeddings, documents, metadatas, ids):\n",
        "        self.embeddings.extend(embeddings)\n",
        "        self.documents.extend(documents)\n",
        "        self.metadatas.extend(metadatas)\n",
        "        self.ids.extend(ids)\n",
        "\n",
        "    def query(self, query_embeddings, n_results=5):\n",
        "        if not self.embeddings:\n",
        "            return {'ids': [[]], 'documents': [[]], 'metadatas': [[]], 'distances': [[]]}\n",
        "\n",
        "        similarities = cosine_similarity(query_embeddings, self.embeddings)[0]\n",
        "        top_indices = np.argsort(similarities)[::-1][:n_results]\n",
        "\n",
        "        return {\n",
        "            'ids': [[self.ids[i] for i in top_indices]],\n",
        "            'documents': [[self.documents[i] for i in top_indices]],\n",
        "            'metadatas': [[self.metadatas[i] for i in top_indices]],\n",
        "            'distances': [[1 - similarities[i] for i in top_indices]]\n",
        "        }\n",
        "\n",
        "    def count(self):\n",
        "        return len(self.documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c447dd6c",
      "metadata": {
        "id": "c447dd6c"
      },
      "outputs": [],
      "source": [
        "class EcologicalRAG:\n",
        "    \"\"\"Main RAG system for ecological research papers\"\"\"\n",
        "\n",
        "    def __init__(self, openai_api_key=None):\n",
        "        self._initialize_components(openai_api_key)\n",
        "        self.papers = []\n",
        "        self.fitted = False\n",
        "\n",
        "    def _initialize_components(self, openai_api_key):\n",
        "        \"\"\"Initialize all system components silently\"\"\"\n",
        "        # Setup embedding model\n",
        "        if TRANSFORMERS_AVAILABLE:\n",
        "            try:\n",
        "                self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "                self.use_transformers = True\n",
        "            except Exception:\n",
        "                self._setup_tfidf()\n",
        "        else:\n",
        "            self._setup_tfidf()\n",
        "\n",
        "        # Setup vector store\n",
        "        if CHROMADB_AVAILABLE:\n",
        "            try:\n",
        "                client = chromadb.Client()\n",
        "                try:\n",
        "                    self.collection = client.get_collection(\"ecological_papers\")\n",
        "                except Exception:\n",
        "                    self.collection = client.create_collection(\"ecological_papers\")\n",
        "                self.use_chromadb = True\n",
        "            except Exception:\n",
        "                self.collection = SimpleVectorStore()\n",
        "                self.use_chromadb = False\n",
        "        else:\n",
        "            self.collection = SimpleVectorStore()\n",
        "            self.use_chromadb = False\n",
        "\n",
        "        # Setup OpenAI\n",
        "        if openai_api_key and OPENAI_AVAILABLE:\n",
        "            openai.api_key = openai_api_key\n",
        "            self.use_openai = True\n",
        "        else:\n",
        "            self.use_openai = False\n",
        "\n",
        "    def _setup_tfidf(self):\n",
        "        \"\"\"Setup TF-IDF as fallback\"\"\"\n",
        "        self.use_transformers = False\n",
        "        self.tfidf = TfidfVectorizer(max_features=1000, stop_words='english')\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        \"\"\"Clean and prepare text for processing\"\"\"\n",
        "        if not text:\n",
        "            return \"\"\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        text = re.sub(r'[^\\w\\s\\-\\.\\(\\)]', ' ', text)\n",
        "        return text.strip()\n",
        "\n",
        "    def extract_entities(self, text):\n",
        "        \"\"\"Extract ecological entities from text\"\"\"\n",
        "        entities = {'species': [], 'locations': [], 'methods': []}\n",
        "\n",
        "        # Species (binomial nomenclature)\n",
        "        species = re.findall(r'\\b[A-Z][a-z]+ [a-z]+\\b', text)\n",
        "        entities['species'] = list(set(species))[:3]\n",
        "\n",
        "        # Locations\n",
        "        locations = re.findall(\n",
        "            r'\\b(Mediterranean|Red Sea|Lake Kinneret|Eastern Mediterranean|Levantine)\\b',\n",
        "            text, re.IGNORECASE\n",
        "        )\n",
        "        entities['locations'] = list(set(locations))[:3]\n",
        "\n",
        "        # Methods\n",
        "        methods = re.findall(\n",
        "            r'\\b(PCR|DNA|sequencing|survey|analysis|modeling)\\b',\n",
        "            text, re.IGNORECASE\n",
        "        )\n",
        "        entities['methods'] = list(set(methods))[:3]\n",
        "\n",
        "        return entities\n",
        "\n",
        "    def generate_embeddings(self, texts):\n",
        "        \"\"\"Generate embeddings using available method\"\"\"\n",
        "        if self.use_transformers:\n",
        "            return self.embedding_model.encode(texts, show_progress_bar=False)\n",
        "        else:\n",
        "            if not self.fitted:\n",
        "                self.tfidf.fit(texts)\n",
        "                self.fitted = True\n",
        "            return self.tfidf.transform(texts).toarray()\n",
        "\n",
        "    def load_papers(self, papers_data):\n",
        "        \"\"\"Load papers into the RAG system\"\"\"\n",
        "        valid_papers = [p for p in papers_data if p.get('abstract', '').strip()]\n",
        "\n",
        "        if not valid_papers:\n",
        "            return False\n",
        "\n",
        "        documents, metadatas, ids = [], [], []\n",
        "\n",
        "        for i, paper in enumerate(valid_papers):\n",
        "            text = f\"{paper.get('title', '')} {paper.get('abstract', '')}\"\n",
        "            text = self.preprocess_text(text)\n",
        "\n",
        "            if len(text) < 50:\n",
        "                continue\n",
        "\n",
        "            entities = self.extract_entities(text)\n",
        "\n",
        "            metadata = {\n",
        "                'title': paper.get('title', 'Unknown'),\n",
        "                'authors': paper.get('authors', 'Unknown'),\n",
        "                'journal': paper.get('journal', 'Unknown'),\n",
        "                'year': paper.get('year', 2022),\n",
        "                'doi': paper.get('doi', ''),\n",
        "                'species': ', '.join(entities['species']),\n",
        "                'locations': ', '.join(entities['locations']),\n",
        "                'methods': ', '.join(entities['methods'])\n",
        "            }\n",
        "\n",
        "            documents.append(text)\n",
        "            metadatas.append(metadata)\n",
        "            ids.append(f\"paper_{i}\")\n",
        "\n",
        "        if not documents:\n",
        "            return False\n",
        "\n",
        "        # Generate embeddings\n",
        "        embeddings = self.generate_embeddings(documents)\n",
        "\n",
        "        # Add to vector store\n",
        "        if getattr(self, 'use_chromadb', False):\n",
        "            try:\n",
        "                self.collection.add(\n",
        "                    embeddings=embeddings.tolist(),\n",
        "                    documents=documents,\n",
        "                    metadatas=metadatas,\n",
        "                    ids=ids\n",
        "                )\n",
        "            except Exception:\n",
        "                # Fallback in case of unexpected API mismatch\n",
        "                self.collection = SimpleVectorStore()\n",
        "                self.collection.add(\n",
        "                    embeddings=embeddings,\n",
        "                    documents=documents,\n",
        "                    metadatas=metadatas,\n",
        "                    ids=ids\n",
        "                )\n",
        "        else:\n",
        "            self.collection.add(\n",
        "                embeddings=embeddings,\n",
        "                documents=documents,\n",
        "                metadatas=metadatas,\n",
        "                ids=ids\n",
        "            )\n",
        "\n",
        "        self.papers = valid_papers\n",
        "        return True\n",
        "\n",
        "    def search(self, query, n_results=3):\n",
        "        \"\"\"Search for relevant papers\"\"\"\n",
        "        query_processed = self.preprocess_text(query)\n",
        "        query_embedding = self.generate_embeddings([query_processed])\n",
        "\n",
        "        if getattr(self, 'use_chromadb', False):\n",
        "            results = self.collection.query(\n",
        "                query_embeddings=query_embedding.tolist(),\n",
        "                n_results=n_results\n",
        "            )\n",
        "        else:\n",
        "            results = self.collection.query(\n",
        "                query_embeddings=query_embedding,\n",
        "                n_results=n_results\n",
        "            )\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _generate_openai_response(self, query, papers, search_results):\n",
        "        \"\"\"Generate response using OpenAI\"\"\"\n",
        "        context = \"\\n\\n\".join([\n",
        "            f\"Paper: {papers[i]['title']}\\n\"\n",
        "            f\"Authors: {papers[i]['authors']}\\n\"\n",
        "            f\"Content: {search_results['documents'][0][i][:400]}...\"\n",
        "            for i in range(min(len(search_results['documents'][0]), len(papers)))\n",
        "        ])\n",
        "\n",
        "        prompt = f\"\"\"You are an expert marine ecologist. Answer this question based on the research provided:\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Research Papers:\n",
        "{context}\n",
        "\n",
        "Provide a comprehensive answer citing the research. Focus on Mediterranean and freshwater ecosystems.\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are an expert marine and freshwater ecologist.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                max_tokens=800,\n",
        "                temperature=0.7\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except Exception:\n",
        "            return self._generate_template_response(query, papers, search_results)\n",
        "\n",
        "    def _generate_template_response(self, query, papers, search_results):\n",
        "        \"\"\"Generate template response without OpenAI\"\"\"\n",
        "        response = f\"## Research Findings for: {query}\\n\\n\"\n",
        "\n",
        "        for i, paper in enumerate(papers[:5]):\n",
        "            response += f\"### {i+1}. {paper['title']}\\n\"\n",
        "            response += f\"**Authors:** {paper['authors']}\\n\"\n",
        "            response += f\"**Journal:** {paper['journal']} ({paper['year']})\\n\"\n",
        "\n",
        "            if paper.get('species'):\n",
        "                response += f\"**Species:** {paper['species']}\\n\"\n",
        "            if paper.get('locations'):\n",
        "                response += f\"**Locations:** {paper['locations']}\\n\"\n",
        "            if paper.get('methods'):\n",
        "                response += f\"**Methods:** {paper['methods']}\\n\"\n",
        "\n",
        "            response += f\"**DOI:** {paper['doi']}\\n\\n\"\n",
        "\n",
        "        # Add summary\n",
        "        all_species = set()\n",
        "        all_locations = set()\n",
        "        for paper in papers:\n",
        "            if paper.get('species'):\n",
        "                all_species.update([s.strip() for s in paper['species'].split(',') if s.strip()])\n",
        "            if paper.get('locations'):\n",
        "                all_locations.update([l.strip() for l in paper['locations'].split(',') if l.strip()])\n",
        "\n",
        "        response += \"### Summary\\n\"\n",
        "        if all_species:\n",
        "            response += f\"**Key Species:** {', '.join(list(all_species)[:5])}\\n\"\n",
        "        if all_locations:\n",
        "            response += f\"**Study Regions:** {', '.join(list(all_locations))}\\n\"\n",
        "\n",
        "        return response\n",
        "\n",
        "    def generate_response(self, query, search_results):\n",
        "        \"\"\"Generate response based on search results\"\"\"\n",
        "        if not search_results['documents'][0]:\n",
        "            return \"No relevant papers found for your query.\"\n",
        "\n",
        "        papers = search_results['metadatas'][0]\n",
        "\n",
        "        if getattr(self, 'use_openai', False):\n",
        "            return self._generate_openai_response(query, papers, search_results)\n",
        "        else:\n",
        "            return self._generate_template_response(query, papers, search_results)\n",
        "\n",
        "    def query(self, question, n_results=5):\n",
        "        \"\"\"Main query function\"\"\"\n",
        "        search_results = self.search(question, n_results)\n",
        "        response = self.generate_response(question, search_results)\n",
        "\n",
        "        return {\n",
        "            'question': question,\n",
        "            'response': response,\n",
        "            'papers_found': len(search_results['documents'][0]),\n",
        "            'search_results': search_results\n",
        "        }\n",
        "\n",
        "    def get_status(self):\n",
        "        \"\"\"Get system status\"\"\"\n",
        "        return {\n",
        "            'vector_db': 'ChromaDB' if getattr(self, 'use_chromadb', False) else 'Simple Store',\n",
        "            'embeddings': 'Transformer' if getattr(self, 'use_transformers', False) else 'TF-IDF',\n",
        "            'generation': 'OpenAI GPT' if getattr(self, 'use_openai', False) else 'Template',\n",
        "            'papers_loaded': len(self.papers) if self.papers else 0\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "294de2b7",
      "metadata": {
        "id": "294de2b7"
      },
      "outputs": [],
      "source": [
        "def get_sample_iolr_papers():\n",
        "    return [\n",
        "       {\n",
        "    'title': 'BTEX and PAH contributions to Lake Kinneret water: a seasonal-based study of volatile and semi-volatile anthropogenic pollutants in freshwater sources',\n",
        "    'authors': 'Astrahan, P., Lupu, A., Leibovici, E., and S. Ninio.',\n",
        "    'journal': 'Environmental Science and Pollution Research',\n",
        "    'year': 2023,\n",
        "    'doi': 'https://doi.org/10.1007/s11356-023-26724-9',\n",
        "    'abstract': 'BTEX and PAH contributions to Lake Kinneret water: a seasonal-based study of volatile and semi-volatile anthropogenic pollutants in freshwater sources. Environmental Science and Pollution Research, 30(21):61145-61159'\n",
        "},\n",
        "{\n",
        "    'title': 'Sodium levels and grazing pressure shape natural communities of the intracellular pathogen Legionella',\n",
        "    'authors': 'Bergman, O., Beeri-Shlevin, Y., and S. Ninio.',\n",
        "    'journal': 'Microbiome',\n",
        "    'year': 2023,\n",
        "    'doi': 'https://doi.org/10.1186/s40168-023-01611-0',\n",
        "    'abstract': 'Sodium levels and grazing pressure shape natural communities of the intracellular pathogen Legionella. Microbiome, 11:167'\n",
        "},\n",
        "{\n",
        "    'title': 'Anthropogenic and natural disturbances along a river and its estuary alter the diversity of pathogens and antibiotic resistance mechanisms',\n",
        "    'authors': 'Rubin-Blum M., Harbuzov Z., Cohen R., and P. Astrahan.',\n",
        "    'journal': 'Science of The Total Environment',\n",
        "    'year': 2023,\n",
        "    'doi': 'https://doi.org/10.1016/j.scitotenv.2023.164108',\n",
        "    'abstract': 'Anthropogenic and natural disturbances along a river and its estuary alter the diversity of pathogens and antibiotic resistance mechanisms. Science of The Total Environment, 887:164108'\n",
        "},\n",
        "{\n",
        "    'title': 'The microbial community spatially varies during a Microcystis bloom event in Lake Kinneret',\n",
        "    'authors': 'Schweitzer-Natan, O., Ofek-Lalzar, M., Sher, D., and A. Sukenik.',\n",
        "    'journal': 'Freshwater Biology',\n",
        "    'year': 2023,\n",
        "    'doi': 'https://doi.org/10.1111/fwb.14030',\n",
        "    'abstract': 'The microbial community spatially varies during a Microcystis bloom event in Lake Kinneret. Freshwater Biology, 68(2):349-363'\n",
        "},\n",
        "{\n",
        "    'title': 'Upstream nitrogen availability determines the Microcystis salt tolerance and influences microcystins release in brackish water',\n",
        "    'authors': 'Li X., Li L., Huang Y., Wu H., Sheng S., Jiang X., Chen X., and I. Ostrovsky.',\n",
        "    'journal': 'Water Research',\n",
        "    'year': 2024,\n",
        "    'doi': 'https://doi.org/10.1016/j.watres.2024.121213',\n",
        "    'abstract': 'Upstream nitrogen availability determines the Microcystis salt tolerance and influences microcystins release in brackish water. Water Research, 252:121213'\n",
        "}\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5213c901",
      "metadata": {
        "id": "5213c901"
      },
      "outputs": [],
      "source": [
        "def create_premium_interface(rag_system):\n",
        "    \"\"\"Create elegant Gradio web interface with improved dark theme\"\"\"\n",
        "\n",
        "    def query_papers(question, n_results):\n",
        "        if not question.strip():\n",
        "            return \"Please enter a research question to get started.\"\n",
        "        result = rag_system.query(question, n_results=int(n_results))\n",
        "        return f\"### 🤖 AI Answer\\n{result['response']}\"\n",
        "\n",
        "    def get_system_metrics():\n",
        "        status = rag_system.get_status()\n",
        "        return f\"\"\"\n",
        "        **System Configuration**\n",
        "\n",
        "        Vector Database: {status['vector_db']} 🗄️\n",
        "        Embeddings: {status['embeddings']} 🔮\n",
        "        Generation: {status['generation']} 🤖\n",
        "        Papers Loaded: {status['papers_loaded']} 📚\n",
        "        \"\"\"\n",
        "\n",
        "    # Curated example questions\n",
        "    examples = [\n",
        "        (\"How do BTEX and PAH pollutants contaminate freshwater sources?\", 3),\n",
        "        (\"What seasonal patterns exist for volatile pollutants in Lake Kinneret?\", 3),\n",
        "        (\"How do anthropogenic disturbances affect pathogen diversity in rivers?\", 4),\n",
        "        (\"What antibiotic resistance mechanisms emerge from environmental pollution?\", 3),\n",
        "        (\"How do semi-volatile pollutants impact aquatic ecosystem health?\", 3),\n",
        "    ]\n",
        "\n",
        "    def run_example(idx: int):\n",
        "        q, n = examples[idx]\n",
        "        res = rag_system.query(q, n_results=int(n))\n",
        "        return q, int(n), res[\"response\"]\n",
        "\n",
        "    # Custom CSS with fix for prompt textbox\n",
        "    custom_css = \"\"\"\n",
        "    :root {\n",
        "        --primary-color: #2563eb;\n",
        "        --secondary-color: #1e40af;\n",
        "        --background-color: #0f172a;\n",
        "        --surface-color: #1e293b;\n",
        "        --surface-light: #334155;\n",
        "        --text-primary: #f8fafc;\n",
        "        --text-secondary: #cbd5e1;\n",
        "        --accent-color: #3b82f6;\n",
        "        --success-color: #059669;\n",
        "        --border-color: #475569;\n",
        "    }\n",
        "    .gradio-container { background: linear-gradient(135deg, #0f172a 0%, #1e293b 100%); color: var(--text-primary); font-family: 'Inter','Segoe UI',sans-serif; min-height: 100vh; }\n",
        "    .main-header { background: rgba(30,41,59,.8); backdrop-filter: blur(20px); border-radius: 16px; padding: 2rem; margin: 1rem; box-shadow: 0 8px 32px rgba(0,0,0,.3); border: 1px solid rgba(71,85,105,.3); }\n",
        "    .query-section { background: rgba(30,41,59,.6); backdrop-filter: blur(15px); border-radius: 12px; padding: 1.5rem; box-shadow: 0 4px 20px rgba(0,0,0,.2); border: 1px solid rgba(71,85,105,.2); }\n",
        "    .response-area { background: rgba(30,41,59,.7) !important; border-radius: 12px !important; border: 1px solid rgba(71,85,105,.3) !important; box-shadow: 0 4px 20px rgba(0,0,0,.15) !important; color: var(--text-primary) !important; }\n",
        "    .status-panel { background: linear-gradient(135deg,#1e40af 0%,#3730a3 100%); border-radius: 12px; padding: 1rem; color: white; box-shadow: 0 4px 15px rgba(59,130,246,.2); border: 1px solid rgba(147,197,253,.2); }\n",
        "\n",
        "    .gradio-textbox textarea, .gradio-textbox input { background: rgba(51,65,85,.8) !important; border: 1px solid rgba(71,85,105,.4) !important; border-radius: 8px !important; color: var(--text-primary) !important; font-size: 14px !important; }\n",
        "    .gradio-textbox textarea:focus, .gradio-textbox input:focus { border-color: var(--accent-color) !important; box-shadow: 0 0 0 2px rgba(59,130,246,.2) !important; }\n",
        "    .gradio-button { background: linear-gradient(135deg,var(--primary-color) 0%,var(--secondary-color) 100%) !important; border: none !important; border-radius: 8px !important; color: white !important; font-weight: 600 !important; transition: all .3s ease !important; }\n",
        "    .gradio-button:hover { transform: translateY(-1px) !important; box-shadow: 0 6px 20px rgba(37,99,235,.3) !important; }\n",
        "    .gradio-slider input[type=\"range\"] { background: rgba(51,65,85,.8) !important; }\n",
        "    .gradio-accordion { background: rgba(30,41,59,.5) !important; border: 1px solid rgba(71,85,105,.3) !important; border-radius: 8px !important; }\n",
        "\n",
        "    .examples-grid { display: grid; grid-template-columns: 1fr; gap: .5rem; }\n",
        "    @media (min-width: 900px) {\n",
        "      .examples-grid { grid-template-columns: 1fr 1fr; }\n",
        "    }\n",
        "    .example-btn { text-align: left; white-space: normal; line-height: 1.3; padding: .75rem 1rem; }\n",
        "    .example-meta { opacity: .85; font-size: .9rem; }\n",
        "    .markdown-content h1, .markdown-content h2, .markdown-content h3 { color: var(--text-primary) !important; }\n",
        "    .markdown-content p { color: var(--text-secondary) !important; line-height: 1.6 !important; }\n",
        "    .gradio-label { color: var(--text-primary) !important; font-weight: 500 !important; }\n",
        "\n",
        "    /* Force black text ONLY in the prompt textbox */\n",
        "    #prompt_box textarea,\n",
        "    #prompt_box input[type=\"text\"] {\n",
        "        color: black !important;\n",
        "        caret-color: black !important;\n",
        "    }\n",
        "    #prompt_box textarea::placeholder,\n",
        "    #prompt_box input[type=\"text\"]::placeholder {\n",
        "        color: #111 !important;\n",
        "        opacity: .6 !important;\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    with gr.Blocks(\n",
        "        title=\"Ecological Research Assistant\",\n",
        "        theme=gr.themes.Base(\n",
        "            primary_hue=\"blue\",\n",
        "            secondary_hue=\"slate\",\n",
        "            neutral_hue=\"slate\",\n",
        "            font=gr.themes.GoogleFont(\"Inter\")\n",
        "        ).set(\n",
        "            body_background_fill=\"#0f172a\",\n",
        "            body_text_color=\"#f8fafc\",\n",
        "            background_fill_primary=\"#1e293b\",\n",
        "            background_fill_secondary=\"#334155\",\n",
        "            border_color_primary=\"#475569\",\n",
        "            color_accent=\"#3b82f6\",\n",
        "            color_accent_soft=\"#1e40af\"\n",
        "        ),\n",
        "        css=custom_css\n",
        "    ) as interface:\n",
        "\n",
        "        with gr.Column(elem_classes=\"main-header\"):\n",
        "            gr.HTML(\"\"\"\n",
        "            <div style=\"text-align: center;\">\n",
        "                <h1 style=\"background: linear-gradient(45deg,#60a5fa,#3b82f6);\n",
        "                           -webkit-background-clip: text;\n",
        "                           -webkit-text-fill-color: transparent;\n",
        "                           font-size: 2.5rem; margin: 0; font-weight: 700;\">\n",
        "                    Ecological Research Assistant 🌊\n",
        "                </h1>\n",
        "                <p style=\"font-size: 1.1rem; color: #94a3b8; margin-top: .5rem; font-weight: 400;\">\n",
        "                    AI-powered insights from IOLR marine and freshwater research\n",
        "                </p>\n",
        "            </div>\n",
        "            \"\"\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=3, elem_classes=\"query-section\"):\n",
        "                question_input = gr.Textbox(\n",
        "                    label=\"🔍 Research Question\",\n",
        "                    placeholder=\"Ask about subjects in pollution that interest you\",\n",
        "                    lines=3,\n",
        "                    elem_id=\"prompt_box\",   # ⬅️ הוספה\n",
        "                )\n",
        "                with gr.Row():\n",
        "                    n_results_slider = gr.Slider(\n",
        "                        minimum=1, maximum=5, value=5, step=1,\n",
        "                        label=\"Papers to analyze 📄 \",\n",
        "                    )\n",
        "                    submit_btn = gr.Button(\"Analyze Research 🚀 \", variant=\"primary\")\n",
        "\n",
        "            with gr.Column(scale=1, elem_classes=\"status-panel\"):\n",
        "                system_info = gr.Markdown(get_system_metrics())\n",
        "\n",
        "        response_output = gr.Markdown(label=\"📊 Research Analysis\", elem_classes=\"response-area\", show_label=True)\n",
        "\n",
        "        with gr.Accordion(\"💡 Example Questions\", open=False):\n",
        "            gr.HTML('<div class=\"example-meta\">Try these research questions:</div>')\n",
        "            with gr.Column(elem_classes=\"examples-grid\"):\n",
        "                buttons = []\n",
        "                for i, (q, n) in enumerate(examples):\n",
        "                    btn = gr.Button(f\"🔎 {q}  ·  {n} papers\", elem_classes=\"example-btn\")\n",
        "                    btn.click(\n",
        "                        fn=lambda idx=i: run_example(idx),\n",
        "                        inputs=[],\n",
        "                        outputs=[question_input, n_results_slider, response_output],\n",
        "                    )\n",
        "                    buttons.append(btn)\n",
        "\n",
        "        submit_btn.click(fn=query_papers, inputs=[question_input, n_results_slider], outputs=response_output)\n",
        "        question_input.submit(fn=query_papers, inputs=[question_input, n_results_slider], outputs=response_output)\n",
        "\n",
        "    return interface\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "79de5357",
      "metadata": {
        "id": "79de5357"
      },
      "outputs": [],
      "source": [
        "def initialize_system():\n",
        "    rag_system = EcologicalRAG(openai_api_key=\"OPENAI-API-KEY\")\n",
        "    sample_papers = get_sample_iolr_papers()\n",
        "    rag_system.load_papers(sample_papers)\n",
        "    return rag_system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "12b49089",
      "metadata": {
        "id": "12b49089"
      },
      "outputs": [],
      "source": [
        "def find_available_port(start_port=7860, max_attempts=10):\n",
        "    import socket\n",
        "    for port in range(start_port, start_port + max_attempts):\n",
        "        try:\n",
        "            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "                s.bind(('localhost', port))\n",
        "                return port\n",
        "        except OSError:\n",
        "            continue\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d55ea0a9",
      "metadata": {
        "id": "d55ea0a9"
      },
      "outputs": [],
      "source": [
        "def launch_app():\n",
        "    rag_system = initialize_system()\n",
        "    if GRADIO_AVAILABLE:\n",
        "        interface = create_premium_interface(rag_system)\n",
        "        port = find_available_port()\n",
        "        if port is None:\n",
        "            interface.launch(share=True, show_error=False, quiet=True)\n",
        "        else:\n",
        "            interface.launch(share=True, server_port=port, show_error=False, quiet=True)\n",
        "    else:\n",
        "        # If gradio isn't available, just return the system for programmatic use\n",
        "        return rag_system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "da01dc75",
      "metadata": {
        "id": "da01dc75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "outputId": "865d05a9-19fc-4ea1-ac16-1b1f9949236d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* Running on public URL: https://0c1e40d1159e350e1a.gradio.live\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0c1e40d1159e350e1a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Run the app (uncomment to launch Gradio)\n",
        "if __name__ == \"__main__\":\n",
        "    launch_app()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}